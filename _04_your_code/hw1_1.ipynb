{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1202576a",
   "metadata": {},
   "source": [
    "## 단축키"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a215f",
   "metadata": {},
   "source": [
    "ESC, a : 현재 셀 바로 위에 새로운 코드 셀 추가\n",
    "\n",
    "ESC, b : 현재 셀 바로 아래에 새로운 코드 셀 추가\n",
    "\n",
    "ESC, dd : 현재 셀 삭제\n",
    "\n",
    "ESC, m : 현재 셀을 Markdown 셀로 변환\n",
    "\n",
    "ESC, y : 현재 셀을 Code 셀로 변환\n",
    "\n",
    "ESC, c : 현재 셀 복사\n",
    "\n",
    "ESC, x : 현재 셀 잘라내기\n",
    "\n",
    "ESC, v : 복사하거나 잘라낸 셀을 붙여넣기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0c9d0",
   "metadata": {},
   "source": [
    "## _02_Tensors 폴더 모든 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60e87a",
   "metadata": {},
   "source": [
    "### 1. a_tensor_initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894b7606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.Tensor class\n",
    "t1  = torch.Tensor([1,2,3], device = 'cpu')\n",
    "print(t1.dtype)\n",
    "print(t1.device)\n",
    "print(t1.requires_grad)\n",
    "print(t1.size())\n",
    "print (t1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0584970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "tensor([1., 2., 3.])\n",
      "================================================== 1\n"
     ]
    }
   ],
   "source": [
    "t1_cuda = t1.to(torch.device('cuda'))\n",
    "t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()\n",
    "print(t1_cuda)\n",
    "print(t1_cpu)\n",
    "\n",
    "print(\"=\"* 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bacba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([1,2,3], device ='cpu')\n",
    "print(t2.dtype)\n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb3bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_cuda = t2.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b1f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\n",
    "print(a1.shape, a1.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09cf2be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) 1\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([1])\n",
    "print(a2.shape, a2.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d563d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) 1\n"
     ]
    }
   ],
   "source": [
    "a3 = torch.tensor([1,2,3,4,5])\n",
    "print(a3.shape, a3.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4701a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "a4 = torch.tensor([[1],[2],[3],[4],[5]])\n",
    "print(a4.shape, a4.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801f6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]])\n",
      "tensor([3.])\n",
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "a111 = a4.clone()\n",
    "a111 = a111.to(torch.float32)\n",
    "print(a111.shape)\n",
    "print(a111)\n",
    "a112= torch.mean(a111, dim=0)\n",
    "print(a112)\n",
    "a113= torch.mean(a111, dim=1)\n",
    "print(a113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d00fb291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "a5 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef4f7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([           \n",
    "    [[1],[2]],\n",
    "    [[3],[4]],\n",
    "    [[5],[6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)\n",
    "# 3,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d563aca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([                 \n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)\n",
    "# 3,1,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead9b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "a8 = torch.tensor([\n",
    "    [[[1,2,3],[2,3,4]]],\n",
    "    [[[3,1,1],[4,4,5]]],\n",
    "    [[[5,6,2],[6,3,1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)\n",
    "# 3,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb519400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 \n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)\n",
    "# 3,1,2,3,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1525df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) 2\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 \n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c46910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 5]) 3\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 \n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "# 4,1,5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec24be9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a11 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# ValueError: expected sequence of length 3 at dim 3 (got 2)\u001b[39;49;00m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1,2,3],[4, 5]]],\n",
    "    [[[1,2,3],[4, 5]]],\n",
    "    [[[1,2,3],[4, 5]]],\n",
    "    [[[1,2,3],[4, 5]]],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f9b7f",
   "metadata": {},
   "source": [
    "### b_tensor_initialization_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a45b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "####################################################################################################\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([100,   2,   3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "l1 = [1,2,3]\n",
    "t1 = torch.Tensor(l1) # float\n",
    "\n",
    "l2 = [1,2,3]\n",
    "t2 = torch.tensor(l2) # int\n",
    "\n",
    "l3  = [1,2,3]\n",
    "t3 = torch.as_tensor(l3) # int\n",
    "\n",
    "l1[0] = 100 \n",
    "l2[0] = 100\n",
    "l3[0] = 100\n",
    "\n",
    "# 위에 작업이 필요한 이유는 :  각각 type이 다른데 값을 int로 넣어주면 어떻게 되는지 파악도 가능하지만, 실제 값이 바뀌는지 파악하기 위함\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "print(\"#\" * 100)\n",
    "\n",
    "l4 = np.array([1,2,3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1,2,3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1,2,3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100\n",
    "l5[0] =100\n",
    "l6[0] =100\n",
    "# 이번에 이 작업이 필요한 이유는 : 타입이 아닌, 실제로 값이 바뀌는지를 파악하기 위함\n",
    "# 결론 : as_tensor는 원본이 바뀌면 마치 C처럼 연결되어있는 느낌\n",
    "\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f233c91",
   "metadata": {},
   "source": [
    "### c_tensor_initialization_constant_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9aa74b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([7.0065e-45, 0.0000e+00, 3.0000e+00, 0.0000e+00])\n",
      "tensor([2.3694e-38, 1.4013e-45, 0.0000e+00, 0.0000e+00])\n",
      "tensor([0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.ones(size=(5,)) # torch.ones(5) \n",
    "t1_like = torch.ones_like(input = t1)\n",
    "print(t1)\n",
    "print(t1_like)\n",
    "# tensor([1., 1., 1., 1., 1.])\n",
    "# tensor([1., 1., 1., 1., 1.])\n",
    "\n",
    "# 궁금증 : 왜 ones해서 5*5가 아님? 왜 shape = 5,1 ?? -> # 5개의 1로 채워진 1차원 텐서 생성\n",
    "\n",
    "t2 = torch.zeros(size=(6,))\n",
    "t2_like = torch.zeros_like(input=t2)\n",
    "print(t2)\n",
    "print(t2_like)\n",
    "\n",
    "# 이거는 위에꺼랑 같은 개념이라 궁금증 해결\n",
    "\n",
    "t3 = torch.empty(size=(4,))\n",
    "t3_like = torch.empty_like(input=t3)\n",
    "print(t3)\n",
    "print(t3_like)\n",
    "# tensor([9.4713e-30, 1.4559e-42, 3.0000e+00, 0.0000e+00])\n",
    "# tensor([9.4714e-30, 1.4559e-42, 3.0000e+00, 0.0000e+00]\n",
    "\n",
    "# 위에꺼는 왜 저런 값이 나오는지? -> 초기화되지 않은 상태의 메모리를 할당받아서 그렇다. (쓰레기 값)\n",
    "print(t3.zero_()) # 0으로 초기화해봄. -> 되는지 확인해본건데 되네\n",
    "\n",
    "t4 = torch.eye(n=3)\n",
    "print(t4)\n",
    "# 3*3 단위행렬 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701de318",
   "metadata": {},
   "source": [
    "### d_tensor_initialization_random_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdd0e190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13, 10]])\n",
      "tensor([[0.9918, 0.1667, 0.2059]])\n",
      "tensor([[ 1.9037, -0.6024,  0.7043]])\n",
      "tensor([[ 8.0602,  8.0026],\n",
      "        [10.8716, 10.1955],\n",
      "        [ 9.2158,  8.3684]])\n",
      "tensor(9.1190)\n",
      "tensor([0.0000, 2.5000, 5.0000])\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "##############################\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.randint(low=10,high=20, size=(1,2))\n",
    "print(t1)\n",
    "\n",
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)\n",
    "\n",
    "t3 = torch.randn(size=(1,3))\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3,2))\n",
    "print(t4)\n",
    "# 평균이 10이고, 표준편차가 1인 정규분포에서 값을 뽑아서 3*2 텐서 생성\n",
    "# 저렇다면 저거들 다 더하고 나누면 평균 10이 되나? -> 이론적으로는 맞지만, 실제로는 다를 수 있음\n",
    "print(torch.mean(t4)) # tensor(9.9343)이 나오네\n",
    "\n",
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)\n",
    "# 0부터 시작해서 5까지 3등분 혹은 3 걸음\n",
    "\n",
    "t6 = torch.arange(5)\n",
    "print(t6)\n",
    "# 0부터 4까지 그래서 5개의 숫자가 생성\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2,3)\n",
    "print(random1)\n",
    "# seed 를 고정시켜서 random 값이 항상 동일함\n",
    "\n",
    "random4 = torch.rand(2,3)\n",
    "print(random4)\n",
    "# 위에서 이미 고정해서 똑같은 값이 나오는 것.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a1814",
   "metadata": {},
   "source": [
    "### e_tensor_type_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "653b2e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int16\n",
      "torch.float64\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones((2,3)) # torch.ones(2,3)와 동일한것으로 파악함 이유는? ->\n",
    "print(a.dtype)\n",
    "\n",
    "b = torch.ones((2,3), dtype = torch.int16)\n",
    "print(b.dtype)\n",
    "\n",
    "c = torch.rand((2,3), dtype = torch.float64) * 20.\n",
    "print(c.dtype)\n",
    "\n",
    "d = b.to(torch.int32)\n",
    "print(d)\n",
    "\n",
    "double_d = torch.ones(10, 20, dtype= torch.double)\n",
    "short_e = torch.tensor([1,2], dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10,2).double() # float64 로 받기\n",
    "short_e = torch.ones(10, 2 ).short() # int16 으로 받기\n",
    "\n",
    "double_d = torch.zeros(10, 2).to(torch.double) # float64 로 받기\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short) # int16 으로 받기\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double) # float64 로 받기\n",
    "short_e = torch.ones(10,2).type(dtype =torch.short) # int16 으로 받기\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print((double_f * short_g).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d36806",
   "metadata": {},
   "source": [
    "### f_tensor_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a235de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "##############################\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "##############################\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "##############################\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.ones(size =(2,3))\n",
    "t2 = torch.ones(size=(2,3))\n",
    "t3 =torch.add(t1,t2)\n",
    "t4 = t1 +t2\n",
    "print(t3)\n",
    "print(t4)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 -t2\n",
    "print(t5)\n",
    "print(t6)\n",
    "# 예상으론 2,3 으로 둘다 0으로 채워짐\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t7 = torch.mul(t1,t2)\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)\n",
    "# 예상으론 2,3 으로 둘 다 1로 채워짐 \n",
    "print(\"#\" * 30)\n",
    "\n",
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)\n",
    "# 예상으론 2,3 으로 둘 다 1로 채워짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b5e25",
   "metadata": {},
   "source": [
    "### g_tensor_operations_mm Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fa89e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) torch.Size([])\n",
      "tensor([[1.6750, 2.2840],\n",
      "        [0.0956, 1.0294]]) torch.Size([2, 2])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.dot(\n",
    "    torch.tensor([2,3]), torch.tensor([2,1])\n",
    ")\n",
    "print(t1, t1.size())\n",
    "\n",
    "t2 = torch.randn(2,3)\n",
    "t3 = torch.randn(3,2)\n",
    "t4 = torch.mm(t2,t3) # matrix multiplication라고 한국말론 행렬곱이라고 한다. 계산법은 ? -> 2*3 , 3*2 -> 2*2\n",
    "print(t4,t4.size())\n",
    "\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "t7 = torch.bmm(t5, t6) # batch matrix multiplication라고 한국말론 배치 행렬곱? 이라고 한다. 계산법은 ? -> 10개의 3*4 , 10개의 4*5 -> 10개의 3*5\n",
    "print(t7.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f48e33",
   "metadata": {},
   "source": [
    "dot\n",
    "\n",
    "mm\n",
    "\n",
    "bmm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697c154",
   "metadata": {},
   "source": [
    "### h_tensor_operations_matmul Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda49020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([10, 3, 5])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.randn(3)\n",
    "t2 = torch.randn(3)\n",
    "print(torch.matmul(t1,t2).size())\n",
    "# 근데 이부분에는 왜 size가 안나오지? -> 스칼라 값이기 때문에 그런듯\n",
    "# 암묵적으로 2차원으로 되어야 뭔가 더 해주거나 하는듯\n",
    "t3 = torch.randn(3,4)\n",
    "t4 = torch.randn(4)\n",
    "print(torch.matmul(t3,t4).size())\n",
    "\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(4)\n",
    "print(torch.matmul(t5,t6).size())\n",
    "# 이 경우에는 \n",
    "# t6을  (10), 4, (1) 이렇게 보는건가 싶음\n",
    "\n",
    "t7 = torch.randn(10,3,4)\n",
    "t8 = torch.randn(10, 4,5)\n",
    "print(torch.matmul(t7, t8).size())\n",
    "\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4,5)\n",
    "print(torch.matmul(t9,t10).size())\n",
    "# 이 부분 조금 이해 안감 배치 사이즈는 그냥 맞춰준다는거야?\n",
    "# 근데 생각해보니 대량의 데이터의 배치라고 지금 생각해서 그렇지, 컴퓨터가 보기엔 그냥 하나의 차원일 뿐 아닌가? 싶음. 그래서 문제가 없겠다는 생각이 드네.\n",
    "# 그래서 ndim의 개수가 안맞는데 matmul을 하는 경우에는 앞자리를 맞춰주겠구나 싶고, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691a3a7",
   "metadata": {},
   "source": [
    "matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad763d3",
   "metadata": {},
   "source": [
    "### i_tensor_broadcasting Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f128bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n",
      "################################################## 1\n",
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n",
      "################################################## 2\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "################################################## 3\n",
      "torch.Size([3, 28, 28])\n",
      "################################################## 4\n",
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n",
      "################################################## 5\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([5, 3, 4, 1])\n",
      "################################################## 6\n",
      "torch.Size([5, 3, 4, 1])\n",
      "torch.Size([3, 1, 7])\n",
      "torch.Size([3, 3, 3])\n",
      "################################################## 7\n",
      "tensor([5., 5., 5., 5.])\n",
      "tensor([25., 25., 25., 25.])\n",
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1*t2)\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t3 = torch.tensor([[0, 1 ], [2,4], [10, 10]])\n",
    "t4 = torch.tensor([4,5])\n",
    "print(t3-t4)\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "t5 = torch.tensor([[1., 2.],[3.,4.]])\n",
    "print(t5 + 2.0)\n",
    "print(t5 * 2.0)\n",
    "print(t5 / 2.0)\n",
    "print(t5 - 2.0)\n",
    "\n",
    "print(\"#\" * 50, 3)\n",
    "\n",
    "def normalize(x):\n",
    "    return x /255\n",
    "\n",
    "t6 =torch.randn(3,28, 28)\n",
    "print(normalize(t6).size())\n",
    "\n",
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t7 = torch.tensor([[1,2],[0,3]])\n",
    "t8 = torch.tensor([[3,1]])\n",
    "t9 = torch.tensor([[5],[2]])\n",
    "t10 = torch.tensor([7])\n",
    "print(t7 + t8) # 2,2 + 1,2 -> 2,2\n",
    "print(t7 + t9) \n",
    "print(t8 + t9)\n",
    "print(t7 + t10)\n",
    "\n",
    "print(\"#\" * 50 ,5)\n",
    "\n",
    "t11 = torch.ones(4,3,2)\n",
    "t12 = t11 * torch.rand(3,2)\n",
    "print(t12.shape)\n",
    "\n",
    "t13 = torch.ones(4,3,2)\n",
    "t14 = t13 * torch.rand(3,1)\n",
    "print(t14.shape)\n",
    "\n",
    "t15 = torch.ones(4,3,2)\n",
    "t16 = t15 * torch.rand(1,2)\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.ones(5,3,4,1)\n",
    "t18 = torch.rand(3,1,1)\n",
    "print((t17 + t18).size())\n",
    "\n",
    "print(\"#\" * 50 ,6)\n",
    "\n",
    "t19 = torch.empty(5,1,4,1)\n",
    "t20 = torch.empty(3,1,1)\n",
    "print((t19 + t20).size())\n",
    "\n",
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3,1,7)\n",
    "print((t21 + t22).size())\n",
    "\n",
    "t23 = torch.ones(3,3,3)\n",
    "t24 = torch.ones(3,1,3)\n",
    "print((t23 + t24).size())\n",
    "\n",
    "print(\"#\" * 50 ,7)\n",
    "\n",
    "t27 = torch.ones(4) * 5\n",
    "print(t27)\n",
    "\n",
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)\n",
    "\n",
    "exp = torch.arange(1., 5.)\n",
    "a = torch.arange(1.,5.)\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb3e3d",
   "metadata": {},
   "source": [
    "pow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cdb426",
   "metadata": {},
   "source": [
    "### j_linear_regression_dataset_dataloader Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a95b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 50, Input Shape: torch.Size([50, 2]), Target Shape: torch.Size([50, 1])\n",
      "################################################## 1\n",
      "0 - tensor([0.2638, 0.0148]): tensor([-145.3462])\n",
      "1 - tensor([0.3347, 0.0177]): tensor([-145.3580])\n",
      "2 - tensor([0.5295, 0.3932]): tensor([-145.4544])\n",
      "3 - tensor([0.0152, 0.2740]): tensor([-145.3279])\n",
      "4 - tensor([0.2562, 0.1772]): tensor([-145.3158])\n",
      "5 - tensor([0.7240, 0.2712]): tensor([-145.3107])\n",
      "6 - tensor([0.5282, 0.1365]): tensor([-145.3034])\n",
      "7 - tensor([0.5036, 0.5921]): tensor([-145.4119])\n",
      "8 - tensor([0.8255, 0.5440]): tensor([-145.3471])\n",
      "9 - tensor([0.6687, 0.6091]): tensor([-145.4089])\n",
      "10 - tensor([0.6253, 0.9405]): tensor([-145.3800])\n",
      "11 - tensor([0.6994, 0.4283]): tensor([-145.4230])\n",
      "12 - tensor([0.3099, 0.3567]): tensor([-145.4594])\n",
      "13 - tensor([0.6212, 0.9794]): tensor([-145.3226])\n",
      "14 - tensor([0.0826, 0.7808]): tensor([-145.2762])\n",
      "15 - tensor([0.5381, 0.1021]): tensor([-145.4636])\n",
      "16 - tensor([0.2985, 0.2210]): tensor([-145.3118])\n",
      "17 - tensor([0.1837, 0.5597]): tensor([-145.4336])\n",
      "18 - tensor([0.4392, 0.3631]): tensor([-145.2938])\n",
      "19 - tensor([0.4889, 0.9104]): tensor([-145.4148])\n",
      "20 - tensor([0.0821, 0.6133]): tensor([-145.3617])\n",
      "21 - tensor([0.6714, 0.9253]): tensor([-145.2885])\n",
      "22 - tensor([0.8550, 0.5293]): tensor([-145.3620])\n",
      "23 - tensor([0.5615, 0.1939]): tensor([-145.3219])\n",
      "24 - tensor([0.6879, 0.7934]): tensor([-145.4054])\n",
      "25 - tensor([0.8877, 0.5805]): tensor([-145.4529])\n",
      "26 - tensor([0.6342, 0.2641]): tensor([-145.4276])\n",
      "27 - tensor([0.8769, 0.2418]): tensor([-145.2732])\n",
      "28 - tensor([0.2026, 0.8817]): tensor([-145.4462])\n",
      "29 - tensor([0.3102, 0.3996]): tensor([-145.3954])\n",
      "30 - tensor([0.8326, 0.1319]): tensor([-145.4065])\n",
      "31 - tensor([0.7170, 0.5860]): tensor([-145.3375])\n",
      "32 - tensor([0.7812, 0.5926]): tensor([-145.3457])\n",
      "33 - tensor([0.4027, 0.2639]): tensor([-145.3958])\n",
      "34 - tensor([0.7756, 0.4699]): tensor([-145.4395])\n",
      "35 - tensor([0.7215, 0.9499]): tensor([-145.3141])\n",
      "36 - tensor([0.2145, 0.4411]): tensor([-145.4138])\n",
      "37 - tensor([0.4227, 0.3246]): tensor([-145.3562])\n",
      "38 - tensor([0.5006, 0.5766]): tensor([-145.4634])\n",
      "39 - tensor([0.2393, 0.1274]): tensor([-145.4158])\n",
      "40 - tensor([0.8070, 0.7652]): tensor([-145.3243])\n",
      "41 - tensor([0.1131, 0.4774]): tensor([-145.3914])\n",
      "42 - tensor([0.5911, 0.1186]): tensor([-145.4657])\n",
      "43 - tensor([0.6618, 0.6775]): tensor([-145.3832])\n",
      "44 - tensor([0.5029, 0.1503]): tensor([-145.2966])\n",
      "45 - tensor([0.7576, 0.4304]): tensor([-145.4683])\n",
      "46 - tensor([0.5805, 0.7987]): tensor([-145.2941])\n",
      "47 - tensor([0.1372, 0.4213]): tensor([-145.2908])\n",
      "48 - tensor([0.9944, 0.8734]): tensor([-145.2704])\n",
      "49 - tensor([0.2215, 0.2043]): tensor([-145.2706])\n",
      "################################################## 2\n",
      "35 10 5\n",
      "################################################## 3\n",
      "0 - tensor([[0.7812, 0.5926],\n",
      "        [0.3099, 0.3567],\n",
      "        [0.1131, 0.4774],\n",
      "        [0.7240, 0.2712]]): tensor([[-145.3457],\n",
      "        [-145.4594],\n",
      "        [-145.3914],\n",
      "        [-145.3107]])\n",
      "1 - tensor([[0.6879, 0.7934],\n",
      "        [0.5911, 0.1186],\n",
      "        [0.7170, 0.5860],\n",
      "        [0.8769, 0.2418]]): tensor([[-145.4054],\n",
      "        [-145.4657],\n",
      "        [-145.3375],\n",
      "        [-145.2732]])\n",
      "2 - tensor([[0.4889, 0.9104],\n",
      "        [0.6342, 0.2641],\n",
      "        [0.0152, 0.2740],\n",
      "        [0.5036, 0.5921]]): tensor([[-145.4148],\n",
      "        [-145.4276],\n",
      "        [-145.3279],\n",
      "        [-145.4119]])\n",
      "3 - tensor([[0.6714, 0.9253],\n",
      "        [0.5615, 0.1939],\n",
      "        [0.0826, 0.7808],\n",
      "        [0.2985, 0.2210]]): tensor([[-145.2885],\n",
      "        [-145.3219],\n",
      "        [-145.2762],\n",
      "        [-145.3118]])\n",
      "4 - tensor([[0.3347, 0.0177],\n",
      "        [0.1372, 0.4213],\n",
      "        [0.2638, 0.0148],\n",
      "        [0.5381, 0.1021]]): tensor([[-145.3580],\n",
      "        [-145.2908],\n",
      "        [-145.3462],\n",
      "        [-145.4636]])\n",
      "5 - tensor([[0.4392, 0.3631],\n",
      "        [0.8877, 0.5805],\n",
      "        [0.6994, 0.4283],\n",
      "        [0.9944, 0.8734]]): tensor([[-145.2938],\n",
      "        [-145.4529],\n",
      "        [-145.4230],\n",
      "        [-145.2704]])\n",
      "6 - tensor([[0.5006, 0.5766],\n",
      "        [0.8550, 0.5293],\n",
      "        [0.2562, 0.1772],\n",
      "        [0.5282, 0.1365]]): tensor([[-145.4634],\n",
      "        [-145.3620],\n",
      "        [-145.3158],\n",
      "        [-145.3034]])\n",
      "7 - tensor([[0.6687, 0.6091],\n",
      "        [0.4227, 0.3246],\n",
      "        [0.3102, 0.3996],\n",
      "        [0.7215, 0.9499]]): tensor([[-145.4089],\n",
      "        [-145.3562],\n",
      "        [-145.3954],\n",
      "        [-145.3141]])\n",
      "8 - tensor([[0.2026, 0.8817],\n",
      "        [0.2145, 0.4411],\n",
      "        [0.5805, 0.7987]]): tensor([[-145.4462],\n",
      "        [-145.4138],\n",
      "        [-145.2941]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class LinearRegressionDataset(Dataset):\n",
    "  def __init__(self, N=50, m=-3, b=2, *args, **kwargs):\n",
    "    # N: number of samples, e.g. 50\n",
    "    # m: slope\n",
    "    # b: offset\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "    self.x = torch.rand(N, 2)\n",
    "    self.noise = torch.rand(N) * 0.2\n",
    "    self.m = m\n",
    "    self.b = b\n",
    "    self.y = (torch.sum(self.x * self.m) + self.b + self.noise).unsqueeze(-1)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx], self.y[idx]\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "      len(self.x), self.x.shape, self.y.shape\n",
    "    )\n",
    "    return str\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  linear_regression_dataset = LinearRegressionDataset()\n",
    "\n",
    "  print(linear_regression_dataset)\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  for idx, sample in enumerate(linear_regression_dataset):\n",
    "    input, target = sample\n",
    "    print(\"{0} - {1}: {2}\".format(idx, input, target))\n",
    "\n",
    "  train_dataset, validation_dataset, test_dataset = random_split(linear_regression_dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "  print(\"#\" * 50, 2)\n",
    "\n",
    "  print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "  print(\"#\" * 50, 3)\n",
    "\n",
    "  train_data_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  for idx, batch in enumerate(train_data_loader):\n",
    "    input, target = batch\n",
    "    print(\"{0} - {1}: {2}\".format(idx, input, target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337f1eb",
   "metadata": {},
   "source": [
    "### k Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50c5eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 image_lst : 4\n",
      "resize된 image_lst : 4\n",
      "stack된 self.images : torch.Size([4, 3, 256, 256])\n",
      "self.image_labels : torch.Size([4, 1])\n",
      "Data Size: 4, input Shape: torch.Size([4, 3, 256, 256]), Target Shape: torch.Size([4, 1])\n",
      "dog_cat_2d_image_dataset.images.shape :  torch.Size([4, 3, 256, 256])\n",
      "################################################## 1\n",
      "0 - torch.Size([3, 256, 256]): tensor([0])\n",
      "1 - torch.Size([3, 256, 256]): tensor([1])\n",
      "2 - torch.Size([3, 256, 256]): tensor([1])\n",
      "3 - torch.Size([3, 256, 256]): tensor([1])\n",
      "train_dataset 길이 :  3\n",
      "test_dataset 길이 :  1\n",
      "################################################## 2\n",
      "3 1\n",
      "################################################## 3\n",
      "train_data_loader 길이 :  2\n",
      "0 - torch.Size([2, 3, 256, 256]): tensor([[1],\n",
      "        [1]])\n",
      "1 - torch.Size([1, 3, 256, 256]): tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "class DogCat2DImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.image_transforms = transforms.Compose([\n",
    "            transforms.Resize(size=(256, 256)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        dogs_dir = os.path.join(os.path.pardir, \"_00_data\", \"a_image-dog\") \n",
    "        cats_dir = os.path.join(os.path.pardir, \"_00_data\", \"b_image-cats\")  \n",
    "\n",
    "        image_lst = [\n",
    "            Image.open(os.path.join(dogs_dir, \"bobby.jpg\")),\n",
    "            Image.open(os.path.join(cats_dir, \"cat1.png\")),\n",
    "            Image.open(os.path.join(cats_dir, \"cat2.png\")),\n",
    "            Image.open(os.path.join(cats_dir, \"cat3.png\"))\n",
    "        ]\n",
    "        print(\"초기 image_lst :\", len(image_lst)) # 초기 image_lst : 4\n",
    "        image_lst = [self.image_transforms(img) for img in image_lst]\n",
    "        print(\"resize된 image_lst :\", len(image_lst)) # resize된 image_lst : 4\n",
    "        self.images = torch.stack(image_lst, dim=0)\n",
    "        print(\"stack된 self.images :\", self.images.shape) #  torch.Size([4, 3, 256, 256])\n",
    "        self.image_labels = torch.tensor([[0], [1], [1], [1]])\n",
    "        print(\"self.image_labels :\", self.image_labels.shape) # torch.Size([4, 1])\n",
    "        assert len(self.images) == len(self.image_labels) # 에러 안나는것을 보니 동일한가봄\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.image_labels[idx]\n",
    "    \n",
    "    def __str__(self):\n",
    "        str = \"Data Size: {0}, input Shape: {1}, Target Shape: {2}\".format(\n",
    "            len(self.images), self.images.shape, self.image_labels.shape\n",
    "        )\n",
    "        return str\n",
    "if __name__ == \"__main__\":\n",
    "    dog_cat_2d_image_dataset = DogCat2DImageDataset()\n",
    "    print(dog_cat_2d_image_dataset)\n",
    "    print(\"dog_cat_2d_image_dataset.images.shape : \",dog_cat_2d_image_dataset.images.shape)\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    for idx, sample in enumerate(dog_cat_2d_image_dataset):\n",
    "        # enmuerate : 인덱스와 함께 값을 반환\n",
    "        input, target = sample\n",
    "        print(\"{0} - {1}: {2}\".format(idx, input.shape, target))\n",
    "\n",
    "    '''\n",
    "    0 - torch.Size([3, 256, 256]): tensor([0])\n",
    "    1 - torch.Size([3, 256, 256]): tensor([1])\n",
    "    2 - torch.Size([3, 256, 256]): tensor([1])\n",
    "    3 - torch.Size([3, 256, 256]): tensor([1])\n",
    "    '''\n",
    "    train_dataset, test_dataset = random_split(dog_cat_2d_image_dataset, [0.7, 0.3])\n",
    "    print(\"train_dataset 길이 : \", len(train_dataset))  # .size()를 len()으로 수정\n",
    "    print(\"test_dataset 길이 : \", len(test_dataset))  # .size()를 len()으로 수정\n",
    "    '''train_dataset 길이 :  3\n",
    "    test_dataset 길이 :  1'''\n",
    "    print(\"#\" * 50, 2)\n",
    "\n",
    "    print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "    print(\"#\" * 50, 3)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size = 2,\n",
    "        shuffle =True\n",
    "    )\n",
    "    print(\"train_data_loader 길이 : \", len(train_data_loader))  # .size를 len()으로 수정\n",
    "    '''\n",
    "    train_data_loader 길이 :  2\n",
    "    0 - torch.Size([2, 3, 256, 256]): tensor([[0],\n",
    "            [1]])\n",
    "    1 - torch.Size([1, 3, 256, 256]): tensor([[1]])\n",
    "    '''\n",
    "    for idx, batch in enumerate(train_data_loader):\n",
    "        input, target = batch\n",
    "        print(\"{0} - {1}: {2}\".format(idx, input.shape, target))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cf7ca",
   "metadata": {},
   "source": [
    "### L - Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "128ee0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n",
      "################################################## 1\n",
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "################################################## 2\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n",
      "################################################## 3\n",
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "################################################## 4\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntorch.Size([1, 2, 6])\\ntensor([[[ 0,  1,  2,  6,  7,  8],\\n         [ 3,  4,  5,  9, 10, 11]]])'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.zeros([2,1,3])\n",
    "t2 = torch.zeros([2,3,3])\n",
    "t3 = torch.zeros([2,2,3])\n",
    "\n",
    "t4 = torch.cat([t1, t2,t3], dim=1)\n",
    "print(t4.shape) \n",
    "# 예상 : 3, 2, 3, 3\n",
    "# 결과 : torch.Size([2, 6, 3])\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t5 =torch.arange(0,3) # 값 : \n",
    "t6 = torch.arange(3,8) # 값 :  \n",
    "# tensor([0, 1, 2]) tensor([3, 4, 5, 6, 7])\n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0)\n",
    "print(t7.shape)\n",
    "print(t7)\n",
    "# 예상 : 3, 3\n",
    "# 결과 : 8\n",
    "# tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "t8 = torch.arange(0,6).reshape(2,3)\n",
    "t9 = torch.arange(6,12).reshape(2,3)\n",
    "\n",
    "t10 = torch.cat((t8, t9), dim=0)\n",
    "print(t10.size()) \n",
    "print(t10)\n",
    "# 예상 : 2,3\n",
    "# 결과 : torch.Size([4, 3])\n",
    "# tensor([[ 0,  1,  2],\n",
    "#         [ 3,  4,  5],\n",
    "#         [ 6,  7,  8],\n",
    "#         [ 9, 10, 11]])\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim= 1)\n",
    "print(t11.size())\n",
    "print(t11)\n",
    "# 예상 : 3, 2\n",
    "# 결과 : torch.Size([2, 6])\n",
    "# tensor([[ 0,  1,  2,  6,  7,  8],\n",
    "        # [ 3,  4,  5,  9, 10, 11]])\n",
    "print(\"#\" * 50, 3)\n",
    "\n",
    "t12 = torch.arange(0,6).reshape(2,3)\n",
    "t13 = torch.arange(6, 12).reshape(2,3)\n",
    "t14 = torch.arange(12,18).reshape(2,3)\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0)\n",
    "print(t15.size())\n",
    "print(t15)\n",
    "# 예상 : 3, 2, 3\n",
    "# 결과 : \n",
    "'''torch.Size([6, 3])\n",
    "tensor([[ 0,  1,  2],\n",
    "        [ 3,  4,  5],\n",
    "        [ 6,  7,  8],\n",
    "        [ 9, 10, 11],\n",
    "        [12, 13, 14],\n",
    "        [15, 16, 17]])'''\n",
    "t16 = torch.cat((t12, t13, t14), dim=1)\n",
    "print(t15.size())\n",
    "print(t15)\n",
    "# 예상 : 3, 3, 2\n",
    "# 결과 : \n",
    "'''\n",
    "torch.Size([6, 3])\n",
    "tensor([[ 0,  1,  2],\n",
    "        [ 3,  4,  5],\n",
    "        [ 6,  7,  8],\n",
    "        [ 9, 10, 11],\n",
    "        [12, 13, 14],\n",
    "        [15, 16, 17]])'''\n",
    "print(\"#\" *50, 4)\n",
    "\n",
    "t17 = torch.arange(0, 6).reshape(1,2,3)\n",
    "t18 = torch.arange(6, 12).reshape(1,2,3)\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0)\n",
    "print(t19.size())\n",
    "print(t19)\n",
    "# 예상 : 2, 1, 2, 3\n",
    "# 결과 : \n",
    "'''torch.Size([2, 2, 3])\n",
    "tensor([[[ 0,  1,  2],\n",
    "         [ 3,  4,  5]],\n",
    "\n",
    "        [[ 6,  7,  8],\n",
    "         [ 9, 10, 11]]])'''\n",
    "t20 = torch.cat((t17,t18), dim=1)\n",
    "print(t20.size())\n",
    "print(t20)\n",
    "# 예상 : \n",
    "# 결과 : \n",
    "'''\n",
    "torch.Size([1, 4, 3])\n",
    "tensor([[[ 0,  1,  2],\n",
    "         [ 3,  4,  5],\n",
    "         [ 6,  7,  8],\n",
    "         [ 9, 10, 11]]])'''\n",
    "t21 = torch.cat((t17, t18), dim= 2)\n",
    "print(t21.size())\n",
    "print(t21)\n",
    "# 예상 : \n",
    "# 결과 : \n",
    "'''\n",
    "torch.Size([1, 2, 6])\n",
    "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
    "         [ 3,  4,  5,  9, 10, 11]]])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec2cba",
   "metadata": {},
   "source": [
    "arange -> reshape\n",
    "\n",
    "cat + dim 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d945f",
   "metadata": {},
   "source": [
    "### m Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6dc46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 3, 2]) True\n",
      "################################################## 1\n",
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "True\n",
      "torch.Size([3, 2])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([[1,2,3], [4,5,6]]) # 2 3\n",
    "t2 = torch.tensor([[7,8,9], [10,11,12]]) # 2 3\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0)\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)\n",
    "print(t3.shape, t3.equal(t4))\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim= 1)\n",
    "t6 = torch.cat([t1.unsqueeze(dim =1), t2.unsqueeze(dim=1)], dim=1)\n",
    "print(t5.shape, t5.equal(t6))\n",
    "\n",
    "t7 = torch.stack([t1,t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)],dim=2)\n",
    "print(t7.shape, t7.equal(t8))\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t9 = torch.arange(0,3)\n",
    "t10 = torch.arange(3,6)\n",
    "\n",
    "print( t9.size(), t10.size())\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim= 0)\n",
    "print(t11.size())\n",
    "print(t11)\n",
    "\n",
    "t12 = torch.cat ((t9.unsqueeze(0), t10.unsqueeze(0)),dim =0)\n",
    "print(t11.equal(t12))\n",
    "\n",
    "t13 = torch.stack((t9, t10), dim=1)\n",
    "print(t13.size())\n",
    "print(t13)\n",
    "\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405cb1a8",
   "metadata": {},
   "source": [
    "Stack\n",
    "\n",
    "cat\n",
    "\n",
    "unsqueeze\n",
    "\n",
    "dim =0\n",
    "\n",
    "dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bc7e3",
   "metadata": {},
   "source": [
    "### n Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1471c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n",
      "################################################## 1\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.tensor([1,2,3])\n",
    "t2 = torch.tensor([4,5,6])\n",
    "t3 = torch.vstack((t1, t2))\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.tensor([[1],[2],[3]])\n",
    "t5 = torch.tensor([[4],[5],[6]])\n",
    "t6 = torch.vstack((t4, t5))\n",
    "\n",
    "t7 = torch.tensor([\n",
    "    [[1,2,3],[4,5,6]],\n",
    "    [[7,8,9],[10,11,12]]\n",
    "])\n",
    "print(t7.shape)\n",
    "\n",
    "t8 = torch.tensor([\n",
    "    [[13,14,15], [16,17,18]],\n",
    "    [[19,20,21],[22,23,24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "\n",
    "t9 = torch.vstack([t7,t8])\n",
    "print(t9.shape)\n",
    "print(t9)\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t10 = torch.tensor([1,2,3])\n",
    "t11 = torch.tensor([4,5,6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "print(t12)\n",
    "\n",
    "t13 = torch.tensor([[1],[2],[3]])\n",
    "t14 = torch.tensor([[4],[5],[6]])\n",
    "t15 = torch.hstack((t13, t14))\n",
    "print(t15)\n",
    "\n",
    "t16 = torch.tensor([\n",
    "    [[1,2,3],[4,5,6]],\n",
    "    [[7,8,9],[10,11,12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "    [[13,14,15],[16,17,18]],\n",
    "    [[19,20,21],[22,23,24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "\n",
    "t18 = torch.hstack([t16,t17])\n",
    "print(t18.shape)\n",
    "\n",
    "print(t18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebfdb13",
   "metadata": {},
   "source": [
    "vstack\n",
    "\n",
    "hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85302b73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca025b45",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "link_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
